summary(m4)
anova(m4)
m4.df <- HSD.test(m4, "SR", group = TRUE, console = TRUE)
with(df, plot(SR, CE))
m5 <- lm(CE ~ SR, data = df)
summary(m5)
anova(m5)
m5.df <- HSD.test(m5, "SR", group = TRUE, console = TRUE)
with(df, plot(SR, SE))
m6 <- lm(SE ~ SR, data = df)
summary(m6)
anova(m6)
m6.df <- HSD.test(m6, "SR", group = TRUE, console = TRUE)
with(df, plot(SR, CE, col = "blue"))
with(df, points(SR, SE, col = "red"))
abline(h = 0) #Just to make it easier to tell positive from negative
with(df, plot(SR, d_Y, ylim = c(-0.05, 0.25)))
#and add a horizontal line:
abline(h = 0)
m4 <- lm(NBE ~ SR, data = df)
summary(m4) #This is our old friend from question 2.
m7 <- lm(NBE ~ PSV, data = df)
summary(m7) # What about phylogenetic diversity?
m8 <- lm(NBE ~ FDis, data = df)
summary(m8) # Or functional diversity?
library(ggplot2)
library(plyr)
###
#let's simulate a diversity experiment with monocultures and polycultures
###
set.seed(2202)
mono <- 8
n <- 8
SIMdf <- data.frame(sp = sort(rep(c(LETTERS[1:mono], "Poly"), n)),
div = c(rep(1, mono*n), rep(mono, n)))
head(SIMdf)
SIMdf
3.5*as.vector(replicate(mono+1, rep(rnorm(1), n)))
#### we sample some compositional effect from a random distribution for ALL treatments
#### there is no biology here - just that each composition has some random variation
SIMdf$compEffect <- 3.5*as.vector(replicate(mono+1, rep(rnorm(1), n)))
SIMdf$compEffect + rnorm(nrow(SIMdf), SIMdf$div)
#now we calculate the yield where there is a linear
SIMdf$y <- SIMdf$compEffect + rnorm(nrow(SIMdf), SIMdf$div)
head(SIMdf)
qplot(div, y, data = SIMdf) + theme_bw()+stat_smooth(method = "lm")
summary(lm(y ~ div, data = SIMdf))
ddply(SIMdf, c("sp", "div"), summarise, ymean = mean(y),
ymin = quantile(y, 0.025), ymax = quantile(y, 0.975))
#look at the mono/poly difference visually
SIMdfSummarized <- ddply(SIMdf, c("sp", "div"), summarise, ymean = mean(y),
ymin = quantile(y, 0.025), ymax = quantile(y, 0.975))
ggplot(SIMdfSummarized, aes(x = sp, y = ymean, ymin = ymin, ymax = ymax)) +
geom_pointrange() + theme_bw()
intPolyLevels <- choose(mono, mono-1)
choose(mono, mono-1)
intPolyLevels
mono-1
LETTERS[1:mono]
rep(combn(LETTERS[1:mono], mono-1, FUN = function(x) paste(x, collapse = "")), n)
intPoly <- rep(combn(LETTERS[1:mono], mono-1, FUN = function(x) paste(x, collapse = "")), n)
rep(rnorm(intPolyLevels)*3.5, n)
polyCompEffect <- rep(rnorm(intPolyLevels)*3.5, n)
polyY <- polyCompEffect + rnorm(length(intPoly), mono-1)
polyY
polyY <- polyCompEffect + rnorm(length(intPoly), mono-1)
#now, let's see what would have happened with intermediate treatments
#let's look at the new experiment
SIMdf <- rbind(SIMdf, data.frame(sp = intPoly, div = mono-1,
compEffect = polyCompEffect, y = polyY))
SIMdf
qplot(div, y, data = SIMdf) + theme_bw()+stat_smooth(method = "lm")
summary(lm(y ~ div, data = SIMdf))
##
#now let's look at everything by treatment
##
SIMdfSummarized <- ddply(SIMdf, c("sp", "div"), summarise,
ymean = mean(y), ymin = quantile(y, 0.025), ymax = quantile(y,0.975))
ggplot(SIMdfSummarized, aes(x = sp, y = ymean, ymin = ymin, ymax = ymax)) +
geom_pointrange() + theme_bw()
datoG0 <- read.table("Data/Environment/bio_var_CCSM_0k_global.txt", h = T)
head(datoG0)
datoG0[1:5, 1:5]
dim(datoG0)
str(datoG0)
summary(datoG0)
class(datoG0)
names(datoG0)
gridded(datoG0) <- ~long+lat
library(vegan)
library(vegan)
library(raster)
library(psych)
library(maps)
library(maptools)
library(kernlab)
gridded(datoG0) <- ~long+lat
class(datoG0)
clima0k <- stack(datoG0)
plot(clima0k$bio.1)
map(add = T)
plot(clima0k$bio.1)
map(add = T)
library(vegan)
library(raster)
library(sp)
library(psych)
library(maps)
library(maptools)
library(kernlab)
datoG0 <- read.table("Data/Environment/bio_var_CCSM_0k_global.txt", h = T)
head(datoG0)
datoG0[1:5, 1:5]
dim(datoG0)
str(datoG0)
summary(datoG0)
class(datoG0)
names(datoG0)
gridded(datoG0) <- ~long+lat
class(datoG0)
clima0k <- stack(datoG0)
plot(clima0k$bio.1)
map(add = T)
# Set a geographical extension (Sur America long = -90, -30, lat = -60, 15)
e <- extent(c(-90, -30, -60, 15))
clima0k.SA <- crop(clima0k, e)
plot(clima0k.sa$bio.9)
clima0k.SA <- crop(clima0k, e)
plot(clima0k.sa$bio.9)
plot(clima0k.SA$bio.9)
map(add = T)
ncell(clima0k.sa)
ncell(clima0k.SA)
SA0k <- values(clima0k.sa)
SA0k <- values(clima0k.SA)
class(SA0k)
coord.SA <- xyFromCell(clima0k.SA, 1:ncell(clima0k.SA))
SA0k <- cbind(coord.SA, SA0k)
# observar valores de lineas y columnas especificas
SA0k[1:5,]
SA0k[1:5, 1:5]
# Variable selection (exceute a factorial analysis [FA])
fa.parallel(SA0k[, -c(1:3)])
SA0k.fa <- fa(SA0k[, -c(1:3)], nfactors = 5, rotate = "varimax")
library(vegan)
library(raster)
library(sp)
library(psych)
library(maps)
library(maptools)
library(kernlab)
datoG0 <- read.table("Data/Environment/bio_var_CCSM_0k_global.txt", h = T)
gridded(datoG0) <- ~long+lat
class(datoG0)
clima0k <- stack(datoG0)
# Set a geographical extension (Sur America long = -90, -30, lat = -60, 15)
e <- extent(c(-90, -30, -60, 15))
clima0k.SA <- crop(clima0k, e)
SA0k <- values(clima0k.SA)
coord.SA <- xyFromCell(clima0k.SA, 1:ncell(clima0k.SA))
SA0k <- cbind(coord.SA, SA0k)
SA0k.fa <- fa(SA0k[, -c(1:3)], nfactors = 5, rotate = "varimax")
SA0k[, c("x", "y", "bio.1", "bio.12", "bio.4", "bio.12", "bio.15")]
#6. Guardar las variables seleccionadas
write.table(SA0k[, c("x", "y", "bio.1", "bio.12", "bio.4", "bio.12", "bio.15")],
row.names = FALSE, "Data/Environment/climaSA0k.txt", sep = "\t")
#6. Guardar las variables seleccionadas
write.table(SA0k[, c("x", "y", "bio.1", "bio.2", "bio.4", "bio.12", "bio.15")],
row.names = FALSE, "Data/Environment/climaSA0k.txt", sep = "\t")
#6. Guardar las variables seleccionadas
write.table(SA0k[, c("x", "y", "bio.1", "bio.2", "bio.4", "bio.12", "bio.15")],
row.names = FALSE, "Data/Environment/climaSA0k.txt", sep = "\t")
rm(list = ls())
hyacinth <- gbif("anodorhynchus", "hyacinthinus*", geo = FALSE)
library(vegan)
library(raster)
library(sp)
library(psych)
library(maps)
library(maptools)
library(kernlab)
library(dismo)
hyacinth <- gbif("anodorhynchus", "hyacinthinus*", geo = FALSE)
# how many rows and colums?
dim(hyacinth)
# load the saved Anodorhynchus hyacinthinus data
data(hyacinth)
# how many rows and colums?
dim(hyacinth)
## [1] 3986   130
# select the records that have longitude and latitude data
colnames(hyacinth)
# how many rows and colums?
dim(hyacinth)
## [1] 3986   130
# select the records that have longitude and latitude data
colnames(hyacinth)
hyacinth <- subset(hyacinth, !is.na(lon) & !is.na(lat))
dim(hyacinth)
dim(hyacinth)
## [1] 3703   130
# show some values
hyacinth[1:4, c(1:5, 7:10)]
hyacinth_coords <- hyacinth_geo[, c(114, 84, 77)]
hyacinth_coords <- hyacinth[, c(114, 84, 77)]
head(hyacinth_coords)
head(hyacinth_coords)
dir.create("Data/OCC")
write.csv(hyacinth_coords, "Data/OCC/hyacinth_data.csv")
rm(list = ls())
hyacinth <- read.csv("Data/OCC/hyacinth_data.csv")
head(hyacinth)
hyacinth_coords <- hyacinth[, c(3, 4)]
head(hyacinth_coords)
climSA0k <- read.table("Data/Environment/climaSA0k.txt", h = T)
class(climSA0k)
gridded(climSA0k) <- ~x + y
climSA0k <- stack(climSA0k)
climSA0k
plot(climSA0k$bio.1)
points(hyacinth_coords[,"lon"], hyacinth_coords[,"lat"])
hyacinth_var <- extract(climSA0k, hyacinth_coords, cellnumbers = T)
head(hyacinth_var)
hyacinth_var <- cbind(hyacinth_coords, hyacinth_var)
hyacinth_var[1:5, ]
hyacinth_var <- na.omit(hyacinth_var) # remove NA's
dim(hyacinth_var)
#3. Eliminar puntos duplicados
duplicated(hyacinth_var[,"cells"])
a <- which(duplicated(hyacinth_var[, "cells"]) == T)
a
hyacinth_var <- hyacinth_var[-a, ]
dim(hyacinth_var)
write.table(hyacinth_var, row.names = FALSE, "Data/OCC/hyacinth_var.txt", sep = "\t")
plot(climSA0k$bio.1)
points(hyacinth_var[, "lon"], hyacinth_var[, "lat"])
clima0k <- read.table("Data/Environment/climaSA0k.txt", h = T)
dim(clima0k)
id.back <- sample(1:nrow(clima0k), 123) #123 is the same number of TRUE occurrences
length(id.back)
background <- clima0k[id.back, ]
dim(background)
names(background)
write.table(background, "Data/Environment/background.txt", row.names = F, sep = "\t")
id.ocur <- sample(1:nrow(hyacinth_var), round(0.75*nrow(hyacinth_var)))
length(id.ocur)
id.back <- sample(1:nrow(background), round(0.75*nrow(background)))
length(id.back)
View(hyacinth_var)
training <- prepareData(x = clima0k,
p = hyacinth_var[id.ocur, 1:2],
b = background[id.back, 1:2], xy = T)
training <- prepareData(x = climaSA0k,
p = hyacinth_var[id.ocur, 1:2],
b = background[id.back, 1:2], xy = T)
training <- prepareData(x = climSA0k,
p = hyacinth_var[id.ocur, 1:2],
b = background[id.back, 1:2], xy = T)
test <- prepareData(x = climSA0k,
p = hyacinth_var[-id.ocur, 1:2],
b = background[-id.back,1:2], xy = T)
View(test)
View(training)
View(training)
Bioclim.model <- bioclim(x = training[training[, "pb"] == 1, -c(1:3)])
Bioclim.modelo
Bioclim.model
plot(Bioclim.modelo)
plot(Bioclim.model)
response(Bioclim.modelo)
response(Bioclim.model)
?response
?domain
?bioclim
Gower.model <- domain(x = training[training[, "pb"] == 1, -c(1:3)])
Gower.model
response(Gower.model)
?ksvm
svm.model <- ksvm(pb ~ bio.1 + bio.2 + bio.4 + bio.12 + bio.15, data = training)
response(svm.model)
glm()
?glm
glm.model <- glm(pb ~ bio.1 + bio.2 + bio.4 + bio.12 + bio.15,
data = training, family = binomial(link = "logit"))
Bioclim0k <- predict(object = Bioclim.modelo, x = climSA0k)
Bioclim0k <- predict(object = Bioclim.model, x = climSA0k)
plot(Bioclim0k)
plot(Bioclim0k)
points(training[training[, "pb"]==1,"x"], training[training[, "pb"]==1,"y"])
Gower0k <- predict(clima0k, Gower.modelo)
Gower0k <- predict(climSA0k, Gower.model)
plot(Gower0k)
svm0k <- predict(climSA0k, svm.model)
plot(svm0k)
GLM0k <- predict(climSA0k, glm.model)
plot(GLM0k)
par(mfrow = c(2, 2))
plot(Bioclim0k, main = "bioclim")
plot(Gower0k, main = "Gower")
plot(svm0k, main = "svm")
plot(GLM0k, main = "glm")
Bioclim.eval <- evaluate(p = test[test[, "pb"] == 1, 1:2],
a = test[test[, "pb"] == 0, 1:2],
model = Bioclim.model,
x = clima0k)
Bioclim.eval <- evaluate(p = test[test[, "pb"] == 1, 1:2],
a = test[test[, "pb"] == 0, 1:2],
model = Bioclim.model,
x = climSA0k)
Bioclim.eval
str(Bioclim.eval)
Bioclim.eval@confusion
?evaluate
Gower.eval <- evaluate(p = test[test[, "pb"]==1, 1:2],
a = test[test[, "pb"]==0, 1:2],
model = Gower.model,
x = climSA0k)
svm.eval <- evaluate(p = test[test[, "pb"]==1, 1:2],
a = test[test[, "pb"]==0, 1:2],
model = svm.model,
x = climSA0k)
glm.eval <- evaluate(p = test[test[, "pb"]==1, 1:2],
a = test[test[, "pb"]==0, 1:2],
model = glm.model,
x = climSA0k)
# validate results
par(mfrow = c(2, 2))
plot(Bioclim.eval, "ROC")
plot(Gower.eval, "ROC")
plot(svm.eval, "ROC")
plot(glm.eval, "ROC")
Bioclim.thr <- threshold(Bioclim.eval)
Bioclim.thr
?threshold
bio <- Bioclim.thr$spec_sens
Gower.thr <- threshold(Gower.eval)
svm.thr <- threshold(svm.eval)
glm.thr <- threshold(glm.eval)
gow <- Gower.thr$spec_sens
s <- svm.thr$spec_sens
g <- glm.thr$spec_sens
glm.thr$spec_sens
par(mfrow = c(2, 2))
plot(Bioclim0k > bio, main = "Bioclim")
plot(GLM0k > g, main = "GLM")
plot(Gower0k > gow, main = "Gower")
plot(svm0k > s, main = "SVM")
thrs <- c(bio, gow, s, g)
tmp <- stack(Bioclim0k, Gower0k, GLM0k, svm0k)
mapa.suma <- sum(tmp) # sum
map.sum <- sum(tmp) # sum
par(mfrow = c(2, 2))
plot(map.sum)
plot(map.sum > thrs)
plot(map.sum > 2)
plot(map.sum > 3)
# Combine all thresholds
thrs <- (bio, gow, s, g)
# Combine all thresholds
thrs <- (bio + gow + s + g)
par(mfrow = c(2, 2))
plot(map.sum)
plot(map.sum > thrs)
plot(map.sum > 2)
plot(map.sum > 3)
map.mean <- mean(tmp) # mean
plot(mapa.media)
plot(map.mean)
plot(map.mean)
plot(mapa.media > thrs)
plot(map.mean)
plot(map.mean > thrs)
plot(map.mean > 0.2)
plot(map.mean > 0.3)
par(mfrow = c(2, 2))
plot(map.mean)
plot(map.mean > thrs)
plot(map.mean > 0.2)
plot(map.mean > 0.3)
auc <- sapply(list(Bioclim.eval, Gower.eval, svm.eval, glm.eval, esv), function(x) x@auc)
auc <- sapply(list(Bioclim.eval, Gower.eval, svm.eval, glm.eval), function(x) x@auc)
w <- (auc-0.5)^2
tmp
weighted.mean(tmp[[c("layer.1", "layer.2", "layer.3", "layer.4")]], w)
map.mean.weight <- weighted.mean(tmp[[c("layer.1", "layer.2", "layer.3", "layer.4")]], w)
plot(map.mean.weight)
map.sd <- sd(tmp) # sd
map.sd <- calc(tmp, sd) # sd
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight = "Weighted mean of all models")
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight = "Weighted mean of all models")
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight, main = "Weighted mean of all models")
plot(map.sd = "Standard deviation of all models")
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight, main = "Weighted mean of all models")
plot(map.sd, main = "Standard deviation of all models")
library(spectrolab)
dir_path = system.file("extdata/spec_matrix_meta.csv", package = "spectrolab")
# Read data from the CSV file. If you don't use `check.names` = FALSE when reading
# the csv, R will usually add a letter to the column names (e.g. 'X650') which will
# cause problems when converting the matrix to spectra.
spec_csv = read.csv(dir_path, check.names = FALSE)
dir_path <- system.file("extdata/spec_matrix_meta.csv", package = "spectrolab")
# Read data from the CSV file. If you don't use `check.names` = FALSE when reading
# the csv, R will usually add a letter to the column names (e.g. 'X650') which will
# cause problems when converting the matrix to spectra.
spec_csv <- read.csv(dir_path, check.names = FALSE)
head(spec_csv)
# The sample names are in column 3. Columns 1 and 2 are metadata
achillea_spec = as.spectra(spec_csv, name_idx = 3, meta_idxs = c(1, 2))
# And now you have a spectra object with sample names and metadata...
achillea_spec
# `dir_path` is the directory where our example datasets live
dir_path <- system.file("extdata", "Acer_example", package = "spectrolab")
# Read .sig files
acer_spectra <- read_spectra(path = dir_path, format = "sig")
# Simply print the object
acer_spectra
# Simply print the object
acer_spectra
# Get the dataset's dimensions
dim(acer_spectra)
# Vector of all sample names. Note: Duplicated sample names are permitted
n <- names(achillea_spec)
# Vector of wavelengths
w <- wavelengths(achillea_spec)
# Reflectance matrix
r <- reflectance(achillea_spec)
# Metadata. Use simplify = TRUE to get a vector instead of a data.frame
m <- meta(achillea_spec, "ssp", simplify = TRUE)
# Subset wavelength regions.
spec_sub_vis <- achillea_spec[ , 400:700 ]
# Subset spectra to all entries where sample_name matches "ACHMI_7" or get the first three samples
spec_sub_byname <- achillea_spec["ACHMI_7", ]
spec_sub_byidx <- achillea_spec[ 1:3, ]
acer_spectra_trim <-  acer_spectra[ , wavelengths(acer_spectra, 400, 2400) ]
# Subsetting samples by indexes works and so does subsetting wavelengths by numerics or characters.
spec_sub_byidx[1, "405"] == spec_sub_byidx[1, 405]
# Simple spectra plot
plot(achillea_spec, lwd = 0.75, lty = 1, col = "grey25", main = "All Spectra")
# Stand along quantile plot
plot_quantile(achillea_spec, total_prob = 0.8, col = rgb(1, 0, 0, 0.5), lwd = 0.5, border = TRUE)
title("80% spectral quantile")
plot_regions(achillea_spec, regions = default_spec_regions(), add = TRUE)
# Combined individual spectra, quantiles and shade spectral regions
plot(achillea_spec, lwd = 0.25, lty = 1, col = "grey50", main="Spectra, quantile and regions")
plot_quantile(achillea_spec, total_prob = 0.8, col = rgb(1, 0, 0, 0.25), border = FALSE, add = TRUE)
plot_regions(achillea_spec, regions = default_spec_regions(), add = TRUE)
source("https://github.com/jesusNPL/BiodiversityScience/blob/master/RFunctions/mixR.R")
source("https://raw.githubusercontent.com/jesusNPL/BiodiversityScience/master/RFunctions/mixR.R")
# Make a matrix from a `spectra` object
spec_as_mat = as.matrix(achillea_spec, fix_names = "none")
spec_as_mat[1:4, 1:3]
# Make a matrix from a `spectra` object
spec_as_df = as.data.frame(achillea_spec, fix_names = "none", metadata = TRUE)
spec_as_df[1:4, 1:5]
VIS <- c(400:700)
NIR <- c(800:1300)
SWIR1 <- c(1550:1800)
SWIR2 <- c(2000:2400)
achillea_spec_VIS <- achillea_spec[, VIS]
achillea_spec_VIS
achillea_spec_VIS_df <- as.data.frame(achillea_spec_VIS, fix_names = "none", metadata = TRUE)
achillea_spec_VIS_df[1:5, 1:7]
spec_as_df[1:5, 1:5]
View(spec_as_df)
spec_as_df_clean <- spec_as_df[, 4:2004]
spec_as_df_clean[1:5, 1:5]
achillea_spec_VIS_df_clean <- achillea_spec_VIS_df[, 4:304]
achillea_spec_VIS_df_clean[1:5, 1:5]
achillea_spec_VIS_df_clean <- achillea_spec_VIS_df[, 4:304]
achillea_spec_VIS_df_clean[1:10, 1:5]
spec_as_df_clean <- spec_as_df[, 4:2004]
spec_as_df_clean[1:10, 1:5]
achillea_spec_VIS_df <- as.data.frame(achillea_spec_VIS, fix_names = "none", metadata = TRUE)
achillea_spec_VIS_df[1:10, 1:5]
spec_as_df_clean[, 1]
spec_as_df_clean[1 ,]
spec_as_df_clean[2 ,]
spec_as_df_clean[ , 2]
spec_as_df_clean[ , 3]
spec_as_df_clean_ind1 <- spec_as_df_clean[1, ]
spec_as_df_clean_ind1
spec_as_df_clean_ind1 <- spec_as_df_clean[10, ]
spec_as_df_clean_ind1
as.numeric(spec_as_df_clean_ind1)
Descriptives(as.numeric(spec_as_df_clean_ind1))
hist(as.numeric(spec_as_df_clean_ind1), col = "black")
abline(v = mean(as.numeric(spec_as_df_clean_ind1)), col = "red", lwd = 3)
spec_as_df_clean_ind1 <- spec_as_df_clean[1, ]
spec_as_df_clean_ind1
achillea_spec_VIS_df_clean_ind1 <- achillea_spec_VIS_df_clean[1, ]
achillea_spec_VIS_df_clean_ind1
hist(as.numeric(achillea_spec_VIS_df_clean_ind1), col = "black")
abline(v = mean(as.numeric(achillea_spec_VIS_df_clean_ind1)), col = "red", lwd = 3)
Descriptives(as.numeric(achillea_spec_VIS_df_clean_ind1))
apply(spec_as_df_clean, MARGIN = 1, FUN = Descriptives)
descript_all_individuals <- apply(spec_as_df_clean, MARGIN = 1, FUN = Descriptives)
descript_all_individuals <- apply(spec_as_df_clean, MARGIN = 1, FUN = Descriptives)
descript_all_individuals[[10]]
diversities(spec_as_df_clean)
diversities(achillea_spec_VIS_df_clean)
