adf <- data.frame(sp = sort(rep(c(base::LETTERS()[1:mono], "Poly"), n)), div = c(rep(1,mono*n), rep(mono,n)))
?LETTERS
LETTERS()
LETTERS(1:mono)
###
#let's simulate a diversity experiment with monocultures and polycultures
###
set.seed(2202)
mono <- 8
n <- 8
adf <- data.frame(sp = sort(rep(c(LETTERS()[1:mono], "Poly"), n)), div = c(rep(1,mono*n), rep(mono,n)))
1:mono
adf <- data.frame(sp = sort(rep(c(LETTERS[1:mono], "Poly"), n)), div = c(rep(1,mono*n), rep(mono,n)))
adf
#### we sample some compositional effect from a random distribution for ALL treatments
#### there is no biology here - just that each composition has some random variation
adf$compEffect <- 3.5*as.vector(replicate(mono+1, rep(rnorm(1), n)))
#now we calculate the yield where there is a linear
adf$y <- adf$compEffect + rnorm(nrow(adf), adf$div)
qplot(div, y, data=adf) + theme_bw()+stat_smooth(method="lm")
library(ggplot2)
library(plyr)
qplot(div, y, data=adf) + theme_bw()+stat_smooth(method="lm")
summary(lm(y~div, data=adf))
#look at the mono/poly difference visually
adfSummarized <- ddply(adf, c("sp", "div"), summarise, ymean = mean(y), ymin=quantile(y, 0.025), ymax=quantile(y,0.975))
ggplot(adfSummarized, aes(x=sp, y=ymean, ymin=ymin, ymax=ymax)) + geom_pointrange() + theme_bw()
intPolyLevels <- choose(mono,mono-1)
intPoly <- rep(combn(LETTERS[1:mono], mono-1, FUN=function(x) paste(x, collapse="")), n)
polyCompEffect <- rep(rnorm(intPolyLevels)*3.5, n)
polyY <- polyCompEffect + rnorm(length(intPoly), mono-1)
#now, let's see what would have happened with intermediate treatments
#let's look at the new experiment
adf <- rbind(adf, data.frame(sp=intPoly, div=mono-1, compEffect=polyCompEffect, y=polyY))
qplot(div, y, data=adf) + theme_bw()+stat_smooth(method="lm")
summary(lm(y~div, data=adf))
##
#now let's look at everything by treatment
##
adfSummarized <- ddply(adf, c("sp", "div"), summarise, ymean = mean(y), ymin=quantile(y, 0.025), ymax=quantile(y,0.975))
ggplot(adfSummarized, aes(x=sp, y=ymean, ymin=ymin, ymax=ymax)) + geom_pointrange() + theme_bw()
###
#let's simulate a diversity experiment with monocultures and polycultures
###
set.seed(2202)
mono <- 8
n <- 8
SIMdf <- data.frame(sp = sort(rep(c(LETTERS[1:mono], "Poly"), n)),
div = c(rep(1, mono*n), rep(mono, n)))
#### we sample some compositional effect from a random distribution for ALL treatments
#### there is no biology here - just that each composition has some random variation
SIMdf$compEffect <- 3.5*as.vector(replicate(mono+1, rep(rnorm(1), n)))
#now we calculate the yield where there is a linear
SIMdf$y <- SIMdf$compEffect + rnorm(nrow(SIMdf), SIMdf$div)
qplot(div, y, data = SIMdf) + theme_bw()+stat_smooth(method = "lm")
summary(lm(y ~ div, data = SIMdf))
#look at the mono/poly difference visually
SIMdfSummarized <- ddply(SIMdf, c("sp", "div"), summarise, ymean = mean(y),
ymin = quantile(y, 0.025), ymax = quantile(y, 0.975))
ggplot(SIMdfSummarized, aes(x = sp, y = ymean, ymin = ymin, ymax = ymax)) +
geom_pointrange() + theme_bw()
intPolyLevels <- choose(mono, mono-1)
intPoly <- rep(combn(LETTERS[1:mono], mono-1, FUN = function(x) paste(x, collapse = "")), n)
polyCompEffect <- rep(rnorm(intPolyLevels)*3.5, n)
polyY <- polyCompEffect + rnorm(length(intPoly), mono-1)
#now, let's see what would have happened with intermediate treatments
#let's look at the new experiment
SIMdf <- rbind(SIMdf, data.frame(sp = intPoly, div = mono-1,
compEffect = polyCompEffect, y = polyY))
qplot(div, y, data = SIMdf) + theme_bw()+stat_smooth(method = "lm")
summary(lm(y ~ div, data = SIMdf))
##
#now let's look at everything by treatment
##
SIMdfSummarized <- ddply(SIMdf, c("sp", "div"), summarise,
ymean = mean(y), ymin = quantile(y, 0.025), ymax = quantile(y,0.975))
ggplot(SIMdfSummarized, aes(x = sp, y = ymean, ymin = ymin, ymax = ymax)) +
geom_pointrange() + theme_bw()
comp.cols <- c(rep("red", 12), rep("orange", 28), rep("yellow", 10), rep("green", 1))
with(df, plot(Comp, d_Y, col = comp.cols))
library(agricolae)
comp.cols <- c(rep("red", 12), rep("orange", 28), rep("yellow", 10), rep("green", 1))
with(df, plot(Comp, d_Y, col = comp.cols))
comp.cols <- c(rep("red", 12), rep("orange", 28), rep("yellow", 10), rep("green", 1))
with(df, plot(Comp, d_Y, col = comp.cols))
df <- read.csv("Data/BEF_Lesson_Data.csv",header=T)
names(df)
dim(df)
comp.cols <- c(rep("red", 12), rep("orange", 28), rep("yellow", 10), rep("green", 1))
with(df, plot(Comp, d_Y, col = comp.cols))
m1 <- lm(d_Y ~ Comp, data = df)
summary(m1)
anova(m1) # Use an ANOVA for categorical data
m1.df <- HSD.test(m1, "Comp", group = TRUE, console = TRUE)
with(df,plot(SR,d_Y)) #It's a little hard to assess the pattern graphically
m2 <- lm(d_Y ~ SR, data = df)
summary(m2) #A linear model indicates "no"
anova(m2) #ANOVA confirms this.
anova(m2) #ANOVA confirms this.
with(df, plot(Comp, NBE, col = comp.cols))
m3 <- lm(NBE ~ Comp, data = df)
summary(m3)
anova(m3)
m3.df<- HSD.test(m3, "Comp", group = TRUE, console = TRUE)
with(df, plot(SR, NBE)) #Note: it doesn't make sense to plot NBE of monocultures
m4 <- lm(NBE ~ SR, data = df)
summary(m4)
anova(m4)
m4.df <- HSD.test(m4, "SR", group = TRUE, console = TRUE)
with(df, plot(SR, CE))
m5 <- lm(CE ~ SR, data = df)
summary(m5)
anova(m5)
m5.df <- HSD.test(m5, "SR", group = TRUE, console = TRUE)
with(df, plot(SR, SE))
m6 <- lm(SE ~ SR, data = df)
summary(m6)
anova(m6)
m6.df <- HSD.test(m6, "SR", group = TRUE, console = TRUE)
with(df, plot(SR, CE, col = "blue"))
with(df, points(SR, SE, col = "red"))
abline(h = 0) #Just to make it easier to tell positive from negative
with(df, plot(SR, d_Y, ylim = c(-0.05, 0.25)))
#and add a horizontal line:
abline(h = 0)
m4 <- lm(NBE ~ SR, data = df)
summary(m4) #This is our old friend from question 2.
m7 <- lm(NBE ~ PSV, data = df)
summary(m7) # What about phylogenetic diversity?
m8 <- lm(NBE ~ FDis, data = df)
summary(m8) # Or functional diversity?
library(ggplot2)
library(plyr)
###
#let's simulate a diversity experiment with monocultures and polycultures
###
set.seed(2202)
mono <- 8
n <- 8
SIMdf <- data.frame(sp = sort(rep(c(LETTERS[1:mono], "Poly"), n)),
div = c(rep(1, mono*n), rep(mono, n)))
head(SIMdf)
SIMdf
3.5*as.vector(replicate(mono+1, rep(rnorm(1), n)))
#### we sample some compositional effect from a random distribution for ALL treatments
#### there is no biology here - just that each composition has some random variation
SIMdf$compEffect <- 3.5*as.vector(replicate(mono+1, rep(rnorm(1), n)))
SIMdf$compEffect + rnorm(nrow(SIMdf), SIMdf$div)
#now we calculate the yield where there is a linear
SIMdf$y <- SIMdf$compEffect + rnorm(nrow(SIMdf), SIMdf$div)
head(SIMdf)
qplot(div, y, data = SIMdf) + theme_bw()+stat_smooth(method = "lm")
summary(lm(y ~ div, data = SIMdf))
ddply(SIMdf, c("sp", "div"), summarise, ymean = mean(y),
ymin = quantile(y, 0.025), ymax = quantile(y, 0.975))
#look at the mono/poly difference visually
SIMdfSummarized <- ddply(SIMdf, c("sp", "div"), summarise, ymean = mean(y),
ymin = quantile(y, 0.025), ymax = quantile(y, 0.975))
ggplot(SIMdfSummarized, aes(x = sp, y = ymean, ymin = ymin, ymax = ymax)) +
geom_pointrange() + theme_bw()
intPolyLevels <- choose(mono, mono-1)
choose(mono, mono-1)
intPolyLevels
mono-1
LETTERS[1:mono]
rep(combn(LETTERS[1:mono], mono-1, FUN = function(x) paste(x, collapse = "")), n)
intPoly <- rep(combn(LETTERS[1:mono], mono-1, FUN = function(x) paste(x, collapse = "")), n)
rep(rnorm(intPolyLevels)*3.5, n)
polyCompEffect <- rep(rnorm(intPolyLevels)*3.5, n)
polyY <- polyCompEffect + rnorm(length(intPoly), mono-1)
polyY
polyY <- polyCompEffect + rnorm(length(intPoly), mono-1)
#now, let's see what would have happened with intermediate treatments
#let's look at the new experiment
SIMdf <- rbind(SIMdf, data.frame(sp = intPoly, div = mono-1,
compEffect = polyCompEffect, y = polyY))
SIMdf
qplot(div, y, data = SIMdf) + theme_bw()+stat_smooth(method = "lm")
summary(lm(y ~ div, data = SIMdf))
##
#now let's look at everything by treatment
##
SIMdfSummarized <- ddply(SIMdf, c("sp", "div"), summarise,
ymean = mean(y), ymin = quantile(y, 0.025), ymax = quantile(y,0.975))
ggplot(SIMdfSummarized, aes(x = sp, y = ymean, ymin = ymin, ymax = ymax)) +
geom_pointrange() + theme_bw()
datoG0 <- read.table("Data/Environment/bio_var_CCSM_0k_global.txt", h = T)
head(datoG0)
datoG0[1:5, 1:5]
dim(datoG0)
str(datoG0)
summary(datoG0)
class(datoG0)
names(datoG0)
gridded(datoG0) <- ~long+lat
library(vegan)
library(vegan)
library(raster)
library(psych)
library(maps)
library(maptools)
library(kernlab)
gridded(datoG0) <- ~long+lat
class(datoG0)
clima0k <- stack(datoG0)
plot(clima0k$bio.1)
map(add = T)
plot(clima0k$bio.1)
map(add = T)
library(vegan)
library(raster)
library(sp)
library(psych)
library(maps)
library(maptools)
library(kernlab)
datoG0 <- read.table("Data/Environment/bio_var_CCSM_0k_global.txt", h = T)
head(datoG0)
datoG0[1:5, 1:5]
dim(datoG0)
str(datoG0)
summary(datoG0)
class(datoG0)
names(datoG0)
gridded(datoG0) <- ~long+lat
class(datoG0)
clima0k <- stack(datoG0)
plot(clima0k$bio.1)
map(add = T)
# Set a geographical extension (Sur America long = -90, -30, lat = -60, 15)
e <- extent(c(-90, -30, -60, 15))
clima0k.SA <- crop(clima0k, e)
plot(clima0k.sa$bio.9)
clima0k.SA <- crop(clima0k, e)
plot(clima0k.sa$bio.9)
plot(clima0k.SA$bio.9)
map(add = T)
ncell(clima0k.sa)
ncell(clima0k.SA)
SA0k <- values(clima0k.sa)
SA0k <- values(clima0k.SA)
class(SA0k)
coord.SA <- xyFromCell(clima0k.SA, 1:ncell(clima0k.SA))
SA0k <- cbind(coord.SA, SA0k)
# observar valores de lineas y columnas especificas
SA0k[1:5,]
SA0k[1:5, 1:5]
# Variable selection (exceute a factorial analysis [FA])
fa.parallel(SA0k[, -c(1:3)])
SA0k.fa <- fa(SA0k[, -c(1:3)], nfactors = 5, rotate = "varimax")
library(vegan)
library(raster)
library(sp)
library(psych)
library(maps)
library(maptools)
library(kernlab)
datoG0 <- read.table("Data/Environment/bio_var_CCSM_0k_global.txt", h = T)
gridded(datoG0) <- ~long+lat
class(datoG0)
clima0k <- stack(datoG0)
# Set a geographical extension (Sur America long = -90, -30, lat = -60, 15)
e <- extent(c(-90, -30, -60, 15))
clima0k.SA <- crop(clima0k, e)
SA0k <- values(clima0k.SA)
coord.SA <- xyFromCell(clima0k.SA, 1:ncell(clima0k.SA))
SA0k <- cbind(coord.SA, SA0k)
SA0k.fa <- fa(SA0k[, -c(1:3)], nfactors = 5, rotate = "varimax")
SA0k[, c("x", "y", "bio.1", "bio.12", "bio.4", "bio.12", "bio.15")]
#6. Guardar las variables seleccionadas
write.table(SA0k[, c("x", "y", "bio.1", "bio.12", "bio.4", "bio.12", "bio.15")],
row.names = FALSE, "Data/Environment/climaSA0k.txt", sep = "\t")
#6. Guardar las variables seleccionadas
write.table(SA0k[, c("x", "y", "bio.1", "bio.2", "bio.4", "bio.12", "bio.15")],
row.names = FALSE, "Data/Environment/climaSA0k.txt", sep = "\t")
#6. Guardar las variables seleccionadas
write.table(SA0k[, c("x", "y", "bio.1", "bio.2", "bio.4", "bio.12", "bio.15")],
row.names = FALSE, "Data/Environment/climaSA0k.txt", sep = "\t")
rm(list = ls())
hyacinth <- gbif("anodorhynchus", "hyacinthinus*", geo = FALSE)
library(vegan)
library(raster)
library(sp)
library(psych)
library(maps)
library(maptools)
library(kernlab)
library(dismo)
hyacinth <- gbif("anodorhynchus", "hyacinthinus*", geo = FALSE)
# how many rows and colums?
dim(hyacinth)
# load the saved Anodorhynchus hyacinthinus data
data(hyacinth)
# how many rows and colums?
dim(hyacinth)
## [1] 3986   130
# select the records that have longitude and latitude data
colnames(hyacinth)
# how many rows and colums?
dim(hyacinth)
## [1] 3986   130
# select the records that have longitude and latitude data
colnames(hyacinth)
hyacinth <- subset(hyacinth, !is.na(lon) & !is.na(lat))
dim(hyacinth)
dim(hyacinth)
## [1] 3703   130
# show some values
hyacinth[1:4, c(1:5, 7:10)]
hyacinth_coords <- hyacinth_geo[, c(114, 84, 77)]
hyacinth_coords <- hyacinth[, c(114, 84, 77)]
head(hyacinth_coords)
head(hyacinth_coords)
dir.create("Data/OCC")
write.csv(hyacinth_coords, "Data/OCC/hyacinth_data.csv")
rm(list = ls())
hyacinth <- read.csv("Data/OCC/hyacinth_data.csv")
head(hyacinth)
hyacinth_coords <- hyacinth[, c(3, 4)]
head(hyacinth_coords)
climSA0k <- read.table("Data/Environment/climaSA0k.txt", h = T)
class(climSA0k)
gridded(climSA0k) <- ~x + y
climSA0k <- stack(climSA0k)
climSA0k
plot(climSA0k$bio.1)
points(hyacinth_coords[,"lon"], hyacinth_coords[,"lat"])
hyacinth_var <- extract(climSA0k, hyacinth_coords, cellnumbers = T)
head(hyacinth_var)
hyacinth_var <- cbind(hyacinth_coords, hyacinth_var)
hyacinth_var[1:5, ]
hyacinth_var <- na.omit(hyacinth_var) # remove NA's
dim(hyacinth_var)
#3. Eliminar puntos duplicados
duplicated(hyacinth_var[,"cells"])
a <- which(duplicated(hyacinth_var[, "cells"]) == T)
a
hyacinth_var <- hyacinth_var[-a, ]
dim(hyacinth_var)
write.table(hyacinth_var, row.names = FALSE, "Data/OCC/hyacinth_var.txt", sep = "\t")
plot(climSA0k$bio.1)
points(hyacinth_var[, "lon"], hyacinth_var[, "lat"])
clima0k <- read.table("Data/Environment/climaSA0k.txt", h = T)
dim(clima0k)
id.back <- sample(1:nrow(clima0k), 123) #123 is the same number of TRUE occurrences
length(id.back)
background <- clima0k[id.back, ]
dim(background)
names(background)
write.table(background, "Data/Environment/background.txt", row.names = F, sep = "\t")
id.ocur <- sample(1:nrow(hyacinth_var), round(0.75*nrow(hyacinth_var)))
length(id.ocur)
id.back <- sample(1:nrow(background), round(0.75*nrow(background)))
length(id.back)
View(hyacinth_var)
training <- prepareData(x = clima0k,
p = hyacinth_var[id.ocur, 1:2],
b = background[id.back, 1:2], xy = T)
training <- prepareData(x = climaSA0k,
p = hyacinth_var[id.ocur, 1:2],
b = background[id.back, 1:2], xy = T)
training <- prepareData(x = climSA0k,
p = hyacinth_var[id.ocur, 1:2],
b = background[id.back, 1:2], xy = T)
test <- prepareData(x = climSA0k,
p = hyacinth_var[-id.ocur, 1:2],
b = background[-id.back,1:2], xy = T)
View(test)
View(training)
View(training)
Bioclim.model <- bioclim(x = training[training[, "pb"] == 1, -c(1:3)])
Bioclim.modelo
Bioclim.model
plot(Bioclim.modelo)
plot(Bioclim.model)
response(Bioclim.modelo)
response(Bioclim.model)
?response
?domain
?bioclim
Gower.model <- domain(x = training[training[, "pb"] == 1, -c(1:3)])
Gower.model
response(Gower.model)
?ksvm
svm.model <- ksvm(pb ~ bio.1 + bio.2 + bio.4 + bio.12 + bio.15, data = training)
response(svm.model)
glm()
?glm
glm.model <- glm(pb ~ bio.1 + bio.2 + bio.4 + bio.12 + bio.15,
data = training, family = binomial(link = "logit"))
Bioclim0k <- predict(object = Bioclim.modelo, x = climSA0k)
Bioclim0k <- predict(object = Bioclim.model, x = climSA0k)
plot(Bioclim0k)
plot(Bioclim0k)
points(training[training[, "pb"]==1,"x"], training[training[, "pb"]==1,"y"])
Gower0k <- predict(clima0k, Gower.modelo)
Gower0k <- predict(climSA0k, Gower.model)
plot(Gower0k)
svm0k <- predict(climSA0k, svm.model)
plot(svm0k)
GLM0k <- predict(climSA0k, glm.model)
plot(GLM0k)
par(mfrow = c(2, 2))
plot(Bioclim0k, main = "bioclim")
plot(Gower0k, main = "Gower")
plot(svm0k, main = "svm")
plot(GLM0k, main = "glm")
Bioclim.eval <- evaluate(p = test[test[, "pb"] == 1, 1:2],
a = test[test[, "pb"] == 0, 1:2],
model = Bioclim.model,
x = clima0k)
Bioclim.eval <- evaluate(p = test[test[, "pb"] == 1, 1:2],
a = test[test[, "pb"] == 0, 1:2],
model = Bioclim.model,
x = climSA0k)
Bioclim.eval
str(Bioclim.eval)
Bioclim.eval@confusion
?evaluate
Gower.eval <- evaluate(p = test[test[, "pb"]==1, 1:2],
a = test[test[, "pb"]==0, 1:2],
model = Gower.model,
x = climSA0k)
svm.eval <- evaluate(p = test[test[, "pb"]==1, 1:2],
a = test[test[, "pb"]==0, 1:2],
model = svm.model,
x = climSA0k)
glm.eval <- evaluate(p = test[test[, "pb"]==1, 1:2],
a = test[test[, "pb"]==0, 1:2],
model = glm.model,
x = climSA0k)
# validate results
par(mfrow = c(2, 2))
plot(Bioclim.eval, "ROC")
plot(Gower.eval, "ROC")
plot(svm.eval, "ROC")
plot(glm.eval, "ROC")
Bioclim.thr <- threshold(Bioclim.eval)
Bioclim.thr
?threshold
bio <- Bioclim.thr$spec_sens
Gower.thr <- threshold(Gower.eval)
svm.thr <- threshold(svm.eval)
glm.thr <- threshold(glm.eval)
gow <- Gower.thr$spec_sens
s <- svm.thr$spec_sens
g <- glm.thr$spec_sens
glm.thr$spec_sens
par(mfrow = c(2, 2))
plot(Bioclim0k > bio, main = "Bioclim")
plot(GLM0k > g, main = "GLM")
plot(Gower0k > gow, main = "Gower")
plot(svm0k > s, main = "SVM")
thrs <- c(bio, gow, s, g)
tmp <- stack(Bioclim0k, Gower0k, GLM0k, svm0k)
mapa.suma <- sum(tmp) # sum
map.sum <- sum(tmp) # sum
par(mfrow = c(2, 2))
plot(map.sum)
plot(map.sum > thrs)
plot(map.sum > 2)
plot(map.sum > 3)
# Combine all thresholds
thrs <- (bio, gow, s, g)
# Combine all thresholds
thrs <- (bio + gow + s + g)
par(mfrow = c(2, 2))
plot(map.sum)
plot(map.sum > thrs)
plot(map.sum > 2)
plot(map.sum > 3)
map.mean <- mean(tmp) # mean
plot(mapa.media)
plot(map.mean)
plot(map.mean)
plot(mapa.media > thrs)
plot(map.mean)
plot(map.mean > thrs)
plot(map.mean > 0.2)
plot(map.mean > 0.3)
par(mfrow = c(2, 2))
plot(map.mean)
plot(map.mean > thrs)
plot(map.mean > 0.2)
plot(map.mean > 0.3)
auc <- sapply(list(Bioclim.eval, Gower.eval, svm.eval, glm.eval, esv), function(x) x@auc)
auc <- sapply(list(Bioclim.eval, Gower.eval, svm.eval, glm.eval), function(x) x@auc)
w <- (auc-0.5)^2
tmp
weighted.mean(tmp[[c("layer.1", "layer.2", "layer.3", "layer.4")]], w)
map.mean.weight <- weighted.mean(tmp[[c("layer.1", "layer.2", "layer.3", "layer.4")]], w)
plot(map.mean.weight)
map.sd <- sd(tmp) # sd
map.sd <- calc(tmp, sd) # sd
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight = "Weighted mean of all models")
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight = "Weighted mean of all models")
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight, main = "Weighted mean of all models")
plot(map.sd = "Standard deviation of all models")
par(mfrow = c(2, 2))
plot(map.sum, main = "Sum of all models")
plot(map.mean, main = "Mean of all models")
plot(map.mean.weight, main = "Weighted mean of all models")
plot(map.sd, main = "Standard deviation of all models")
