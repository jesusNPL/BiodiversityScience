noDataValue = myNoDataValue,
extent = rasExt, CRS = myCRS)
# create raster list and then a stack using those two bands
pri_harv <- lapply(pri_bands, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt, CRS = myCRS)
# create raster list and then a stack using those two bands
pri_harv <- lapply(pri_bands, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt, CRS = myCRS)
# Calculate NDVI
# select bands to use in calculation (red, NIR)
ndvi_bands <- c(58, 90) #bands c(58, 90) in full NEON hyperspectral dataset
# create raster list and then a stack using those two bands
ndvi_harv <- lapply(ndvi_bands, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt, CRS = myCRS)
ndvi_harv <- stack(ndvi_harv)
# make the names pretty
bandNDVINames <- paste("Band_", unlist(ndvi_bands), sep = "")
names(ndvi_harv) <- bandNDVINames
# view the properties of the new raster stack
ndvi_harv
aPixeldf
f
# file: the hdf file
# band: the band you want to process
# noDataValue: values to be omitted
# extent: raster extent
# CRS: coordinates system
# returns: a matrix containing the reflectance data for the specific band
band2Raster <- function(file, band, noDataValue, extent, CRS){
# first, read in the raster
out <- h5read(file, #"/HARV/Reflectance/Reflectance_Data",
index = list(band, NULL, NULL)) # path to the HDF5 file
# Convert from array to matrix
out <- (out[1,,]) # output
# transpose data to fix flipped row and column order
# depending upon how your data are formatted you might not have to perform this
# step.
out <- t(out)
# assign data ignore values to NA
# note, you might chose to assign values of 15000 to NA
out[out == myNoDataValue] <- NA
# turn the out object into a raster
outr <- raster(out, crs = CRS)
# assign the extents to the raster
extent(outr) <- extent
# return the raster object
return(outr)
}
# create a list of the bands we want in our stack
rgb <- list(58, 34, 19)
# lapply tells R to apply the function to each element in the list
rgb_harv <- lapply(rgb, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt,
CRS = myCRS)
H5close()
# create a list of the bands we want in our stack
rgb <- list(58, 34, 19)
# lapply tells R to apply the function to each element in the list
rgb_harv <- lapply(rgb, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt,
CRS = myCRS)
# file: the hdf file
# band: the band you want to process
# noDataValue: values to be omitted
# extent: raster extent
# CRS: coordinates system
# returns: a matrix containing the reflectance data for the specific band
band2Raster <- function(file, band, noDataValue, extent, CRS){
# first, read in the raster
out <- h5read(file, "/HARV/Reflectance/Reflectance_Data",
index = list(band, NULL, NULL)) # path to the HDF5 file
# Convert from array to matrix
out <- (out[1,,]) # output
# transpose data to fix flipped row and column order
# depending upon how your data are formatted you might not have to perform this
# step.
out <- t(out)
# assign data ignore values to NA
# note, you might chose to assign values of 15000 to NA
out[out == myNoDataValue] <- NA
# turn the out object into a raster
outr <- raster(out, crs = CRS)
# assign the extents to the raster
extent(outr) <- extent
# return the raster object
return(outr)
}
# create a list of the bands we want in our stack
rgb <- list(58, 34, 19)
# lapply tells R to apply the function to each element in the list
rgb_harv <- lapply(rgb, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt,
CRS = myCRS)
# check out the properties or rgb_rast
# note that it displays properties of 3 rasters.
rgb_harv
# file: the hdf file
# band: the band you want to process
# noDataValue: values to be omitted
# extent: raster extent
# CRS: coordinates system
# returns: a matrix containing the reflectance data for the specific band
band2Raster <- function(file, path, band, noDataValue, extent, CRS){
# first, read in the raster
out <- h5read(file, "/HARV/Reflectance/Reflectance_Data",
index = list(band, NULL, NULL)) # path to the HDF5 file
# Convert from array to matrix
out <- (out[1,,]) # output
# transpose data to fix flipped row and column order
# depending upon how your data are formatted you might not have to perform this
# step.
out <- t(out)
# assign data ignore values to NA
# note, you might chose to assign values of 15000 to NA
out[out == myNoDataValue] <- NA
# turn the out object into a raster
outr <- raster(out, crs = CRS)
# assign the extents to the raster
extent(outr) <- extent
# return the raster object
return(outr)
}
# create a list of the bands we want in our stack
rgb <- list(58, 34, 19)
# lapply tells R to apply the function to each element in the list
rgb_harv <- lapply(rgb, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt,
CRS = myCRS)
# file: the hdf file
# band: the band you want to process
# noDataValue: values to be omitted
# extent: raster extent
# CRS: coordinates system
# returns: a matrix containing the reflectance data for the specific band
band2Raster <- function(file, band, noDataValue, extent, CRS){
# first, read in the raster
out <- h5read(file, "/HARV/Reflectance/Reflectance_Data",
index = list(band, NULL, NULL)) # path to the HDF5 file
# Convert from array to matrix
out <- (out[1,,]) # output
# transpose data to fix flipped row and column order
# depending upon how your data are formatted you might not have to perform this
# step.
out <- t(out)
# assign data ignore values to NA
# note, you might chose to assign values of 15000 to NA
out[out == myNoDataValue] <- NA
# turn the out object into a raster
outr <- raster(out, crs = CRS)
# assign the extents to the raster
extent(outr) <- extent
# return the raster object
return(outr)
}
# create a list of the bands we want in our stack
rgb <- list(58, 34, 19)
# lapply tells R to apply the function to each element in the list
rgb_harv <- lapply(rgb, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt,
CRS = myCRS)
# check out the properties or rgb_rast
# note that it displays properties of 3 rasters.
rgb_harv
h5closeAll()
# create a list of the bands we want in our stack
rgb <- list(58, 34, 19)
# lapply tells R to apply the function to each element in the list
rgb_harv <- lapply(rgb, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt,
CRS = myCRS)
# check out the properties or rgb_rast
# note that it displays properties of 3 rasters.
rgb_harv
# Create a raster stack from our list of rasters
rgb_harv_stack <- stack(rgb_harv)
rgb_harv_stack
# Calculate NDVI
# select bands to use in calculation (red, NIR)
ndvi_bands <- c(58, 90) #bands c(58, 90) in full NEON hyperspectral dataset
# create raster list and then a stack using those two bands
ndvi_harv <- lapply(ndvi_bands, FUN = band2Raster, file = f,
noDataValue = myNoDataValue,
extent = rasExt, CRS = myCRS)
ndvi_harv <- stack(ndvi_harv)
# make the names pretty
bandNDVINames <- paste("Band_", unlist(ndvi_bands), sep = "")
names(ndvi_harv) <- bandNDVINames
# view the properties of the new raster stack
ndvi_harv
ndvi_harv
aPixel
class(aPixel)
class(b)
# extract all bands from a single pixel
aPixel <- h5read(f, "/HARV/Reflectance/Reflectance_Data", index = list(NULL, 100, 35))
class(aPixel)
# The line above generates a vector of reflectance values.
# Next, we reshape the data and turn them into a dataframe
b <- adply(aPixel, c(1))
class(b)
# create clean data frame
aPixeldf <- b[2]
# add wavelength data to matrix
aPixeldf$Wavelength <- WL
head(aPixeldf)
ggplot(data = aPixeldf) +
geom_line(aes(x = Wavelength, y = ScaledReflectance)) +
xlab("Wavelength (nm)") +
ylab("Reflectance")
scaleFact <- reflInfo$Scale_Factor
# add scaled data column to the data frame
aPixeldf$scaled <- (aPixeldf$V1/as.vector(scaleFact))
# make nice column names
names(aPixeldf) <- c('Reflectance', 'Wavelength', 'ScaledReflectance')
head(aPixeldf)
tail(aPixeldf)
ggplot(data = aPixeldf) +
geom_line(aes(x = Wavelength, y = ScaledReflectance)) +
xlab("Wavelength (nm)") +
ylab("Reflectance")
install.packages("neonhs")
devtools::install_github('earthlab/neonhs')
?click
as.data.frame(WL)
Pixel_df <- as.data.frame(WL)
# loop through each of the cells that we selected
for(i in 1:length(clk$cell)){
# extract Spectra from a single pixel
aPixel <- h5read(f, "/HARV/Reflectance/Reflectance_Data",
index = list(NULL, clk$col[i], clk$row[i]))
# scale reflectance values from 0-1
aPixel <- aPixel/as.vector(scaleFact)
# reshape the data and turn into dataframe
b <- adply(aPixel, c(1))
# rename the column that we just created
names(b)[2] <- paste0("Point_", i)
# add reflectance values for this pixel to our combined data.frame called Pixel_df
Pixel_df <- cbind(Pixel_df, b[2])
}
head(Pixel_df)
head(Pixel_df)
tail(Pixel_df)
?melt
# Use the melt() function to reshape the dataframe into a format that ggplot prefers
Pixel.melt <- melt(Pixel_df, id.vars = "WL", value.name = "Reflectance")
ggplot() +
geom_line(data = Pixel.melt, mapping = aes(x = WL,
y = Reflectance,
color = variable), lwd = 1.5) +
scale_colour_manual(values = c("green2", "green4", "chartreuse3", "tan4", "blue3"),
labels = c("Forest1", "Forest2", "Forest3", "Soil", "Water"))+
labs(color = "Cover Type") +
ggtitle("Land cover spectral signatures") +
theme(plot.title = element_text(hjust = 0.5, size = 20)) +
xlab("Wavelength")
reflMetadata$Band_Window_1_Nanometers
reflMetadata$Band_Window_2_Nanometers
# grab Reflectance metadata (which contains absorption band limits)
reflMetadata <- h5readAttributes(f, "/HARV/Reflectance" )
ab1 <- reflMetadata$Band_Window_1_Nanometers
ab2 <- reflMetadata$Band_Window_2_Nanometers
ab1
ab2
# Plot spectral signatures again with rectangles showing the absorption bands
ggplot() +
geom_line(data = Pixel.melt, mapping = aes(x = WL,
y = Reflectance,
color = variable), lwd = 1.5) +
geom_rect(mapping = aes(ymin = min(Pixel.melt$Reflectance),
ymax = max(Pixel.melt$Reflectance),
xmin = ab1[1], xmax = ab1[2]),
color = "black", fill = "grey40", alpha = 0.8) +
geom_rect(mapping = aes(ymin = min(Pixel.melt$Reflectance),
ymax = max(Pixel.melt$Reflectance),
xmin = ab2[1], xmax = ab2[2]),
color = "black", fill = "grey40", alpha = 0.8) +
scale_colour_manual(values = c("green2", "green4", "chartreuse3", "tan4", "blue3"),
labels = c("Forest1", "Forest2", "Forest3", "Soil", "Water")) +
labs(color = "Cover Type") +
ggtitle("Land cover spectral signatures") +
theme(plot.title = element_text(hjust = 0.5, size = 20)) +
xlab("Wavelength")
# Duplicate the spectral signatures into a new data.frame
Pixel.melt.masked <- Pixel.melt
# Mask out all values within each of the two atmospheric absorbtion bands
Pixel.melt.masked[Pixel.melt.masked$WL >
ab1[1] & Pixel.melt.masked$WL < ab1[2], ]$Reflectance <- NA
Pixel.melt.masked[Pixel.melt.masked$WL >
ab2[1] & Pixel.melt.masked$WL < ab2[2], ]$Reflectance <- NA
head(Pixel.melt.masked)
ggplot() +
geom_line(data = Pixel.melt.masked, mapping = aes(x = WL,
y = Reflectance,
color = variable), lwd = 1.5) +
scale_colour_manual(values = c("green2", "green4", "chartreuse3","tan4","blue3"),
labels = c("Forest1", "Forest2", "Forest3", "Soil", "Water"))+
labs(color = "Cover Type")+
ggtitle("Land cover spectral signatures")+
theme(plot.title = element_text(hjust = 0.5, size=20))+
xlab("Wavelength")
# close the H5 file
H5close()
rm(list = ls())
harv_ndvi <- raster("Data/NEON/DP3.30006.001/HARV_plot_001_NDVI.tif")
plot(ndvi_calc)
harv_ndvi <- raster("Data/NEON/DP3.30006.001/HARV_plot_001_NDVI.tif")
plot(harv_ndvi)
# Computes Shannon's diversity index (H') on different classes of numeric matrices using a moving window algorithm.
HARV_shannon <- Shannon(ndvi_calc, window = 5, np = 2)
# Computes Shannon's diversity index (H') on different classes of numeric matrices using a moving window algorithm.
HARV_shannon <- Shannon(harv_ndvi window = 5, np = 2)
# Computes Shannon's diversity index (H') on different classes of numeric matrices using a moving window algorithm.
HARV_shannon <- Shannon(harv_ndvi, window = 5, np = 2)
library(parallel)
# Computes Shannon's diversity index (H') on different classes of numeric matrices using a moving window algorithm.
HARV_shannon <- Shannon(harv_ndvi, window = 5, np = 2)
library(doParallel)
# Computes Shannon's diversity index (H') on different classes of numeric matrices using a moving window algorithm.
HARV_shannon <- Shannon(harv_ndvi, window = 5, np = 2)
plot(HARV_shannon)
# Computes Hill's index of diversity (Hill numbers) on different classes of numeric matrices using a moving window algorithm.
HARV_hill <- Hill(ndvi_calc, window = 5, np = 2, rasterOut = TRUE)
# Computes Hill's index of diversity (Hill numbers) on different classes of numeric matrices using a moving window algorithm.
HARV_hill <- Hill(harv_ndvi, window = 5, np = 2, rasterOut = TRUE)
?Hill
plot(HARV_hill[[1]])
cor.test(values(HARV_shannon), values(HARV_hill[[1]]))
install.packages("coronavirus")
library(coronavirus)
data("coronavirus")
force(coronavirus)
View(coronavirus)
corona <- refresh_coronavirus_jhu()
head(corona)
# Get top confirmed cases by country
corona_total <- coronavirus %>%
filter(type == "confirmed") %>%
group_by(country) %>%
summarise(total = sum(cases)) %>%
arrange(-total)
library(tidyverse)
# Get top confirmed cases by country
corona_total <- coronavirus %>%
filter(type == "confirmed") %>%
group_by(country) %>%
summarise(total = sum(cases)) %>%
arrange(-total)
# See the 20 countries with more cases
head(corona_total, 20)
corona_total %>%
head(20) %>%
ggplot(aes(y = country, x = total)) +
geom_bar(stat = "identity") +
labs(x = "Number of cases", y = "Countries with more reported cases")
corona_total %>%
tail(20) %>%
ggplot(aes(y = country, x = total)) +
geom_bar(stat = "identity") +
labs(x = "Number of cases", y = "Countries with less reported cases")
packages <- c("coronavirus", "deSolve", "dplyr", "tidyr", "ggplot2", "lubridate",
"phytools", "ape", "phangorn")
lapply(packages, library, character.only = TRUE)
infected_us <- subset(corona_us, data_type == "cases_new")
corona_us <- subset(corona, location == "US")
head(corona_us)
corona_us <- corona_us[order(corona_us$date), ] # sort the data according dates
head(corona_us)
infected_us <- subset(corona_us, data_type == "cases_new")
deaths_us <- subset(corona_us, data_type == "deaths_new")
recovered_us <- subset(corona_us, data_type == "recovered_new")
head(infected_us)
plot(infected_us$date, infected_us$value, type = "b")
Days <- 1:nrow(infected_us)
infected_us <- data.frame(infected_us, Days)
head(infected_us)
plot(infected_us$Days, infected_us$value, type = "b",
ylab = "Infected", xlab = "Days since the first case")
# Get data from the CDC
url_data <- "https://data.cdc.gov/api/views/9mfq-cb36/rows.csv?accessType=DOWNLOAD"
covid_us <- read.csv(url_data)
head(covid_us, 10)
covid_us %>%
arrange(state) %>%
ggplot(aes(y = state, x = tot_cases)) +
geom_bar(stat = "identity") +
labs(x = "Number of cases", y = "Reported cases by State")
covid_us <- covid_us %>%
mutate(Date = submission_date) %>%
mutate(Date2 = mdy(Date)) %>%
separate(submission_date, sep = "/", into = c("month", "day", "year"))
# Sort the data in an increasing order
covid_us <- covid_us[order(covid_us$Date2), ]
head(covid_us)
covid_mn <- subset(covid_us, state == "MN")
head(covid_mn)
plot(1:nrow(covid_mn), covid_mn$new_case, type = "b",
ylab = "Infected Subjects", xlab = "Days since the pandemic started")
plot(1:nrow(covid_mn), covid_mn$tot_cases, type = "b",
ylab = "Total Infected Subjects", xlab = "Days since the pandemic started")
plot(1:nrow(covid_mn), abs(covid_mn$new_death), type = "b",
ylab = "Number of Deaths", xlab = "Days since the pandemic started")
RSS <- function(parameters) {
names(parameters) <- c("Beta", "Gamma")
out <- ode(y = init, times = Days, func = SIR, parms = parameters)
# the out object includes the SIR function we wrote above
fit <- out[, 3]
sum((Infected - fit)^2)
}
N <- 5686649 # Total population for the State of Minnesota for the 2020
start_date <- "2020-03-06"
end_date <- "2020-05-10"
# isolating the infected subjects in the state of Minnesota since the start date
Infected <- subset(covid_mn, Date2 >= ymd(start_date) & Date2 <= ymd(end_date))$new_case
Days <- 1:length(Infected) # Number of days since the first case
plot(Days, Infected, type = "b")
plot(Days, Infected, log = "y")
#abline(lm(log10(Infected) ~ Days))
title("Confirmed Cases 2019-nCoV in MN, first 60 days", outer = TRUE, line = -2)
init <- c(
S = N - Infected[1], # Susceptible group
I = Infected[1], # Infected group
R = 0 # Recovered group.
)
Opt <- optim(c(0.5, 0.5),
RSS,
method = "L-BFGS-B",
lower = c(0, 0),
upper = c(1, 1)
)
init <- c(
S = N - Infected[1], # Susceptible group
I = Infected[1], # Infected group
R = 0 # Recovered group.
)
Opt <- optim(c(0.5, 0.5),
RSS,
method = "L-BFGS-B",
lower = c(0, 0),
upper = c(1, 1)
)
SIR <- function(time, state, parameters) {
par <- as.list(c(state, parameters))
with(par, {
dS <- -Beta * I * S / N # Equation one
dI <- Beta * I * S / N - Gamma * I # Equation two
dR <- Gamma * I # Equation three
list(c(dS, dI, dR))
})
}
Opt <- optim(c(0.5, 0.5),
RSS,
method = "L-BFGS-B",
lower = c(0, 0),
upper = c(1, 1)
)
# optimize with some sensible conditions
Opt$message
# [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
# get the fitted values from our SIR model
fit_incidence <- data.frame(ode(
y = init, times = Days,
func = SIR, parms = Opt_par
))
Opt_par <- setNames(Opt$par, c("Beta", "Gamma"))
Opt_par
# get the fitted values from our SIR model
fit_incidence <- data.frame(ode(
y = init, times = Days,
func = SIR, parms = Opt_par
))
head(fit_incidence)
tail(fit_incidence)
matplot(fit_incidence$time, fit_incidence$I,
type = "l", log = "y",
xlab = "Days", ylab = "Number of infected subjects",
lwd = 2, lty = 1)
points(Days, Infected)
R0 <- setNames(Opt_par["Beta"] / Opt_par["Gamma"], "R0")
round(R0, 3)
times <- 1:150 # time in days
fit_150 <- data.frame(ode(
y = init, times = times,
func = SIR, parms = Opt_par))
head(fit_150)
tail(fit_150)
cols <- 1:3 # colors: black = susceptible, red = infected and green = recovered
matplot(fit_150$time, fit_150[, 2:4], type = "l",
xlab = "Days", ylab = "Number of subjects",
lwd = 2, lty = 1, col = cols)
legend("left", c("Susceptible", "Infected", "Recovered"),
lty = 1, lwd = 2, col = cols, inset = 0.05)
matplot(fit_150$time, fit_150[ , 2:4], type = "l",
xlab = "Days", ylab = "Number of subjects",
lwd = 2, lty = 1, col = cols, log = "y")
## Warning in xy.coords(x, y, xlabel, ylabel, log = log): 1 y value <= 0
## omitted from logarithmic plot
points(Days, Infected)
legend("bottomright", c("Susceptible", "Infected", "Recovered"),
lty = 1, lwd = 2, col = cols, inset = 0.05)
title("SIR model 2019-nCoV United States", outer = TRUE, line = -2)
# Peak of the pandemic for the first 60 days
fit_incidence[fit_incidence$I == max(fit_incidence$I), c("time", "I")]
max(fit_incidence$I) * 0.02 # Assuming 2% of fatality rate
